---
title: Cohort Study
narratives:
---

**Scenario:**

Ishanvi studies racial disparities among African Americans with cardiovascular
diagnoses. She relies on results published in journal articles for guiding
her research. She wants access to the underlying data to have control over
defining her cohort and analysis. At the very least, she wants to
reproduce these studies before trusting them as the basis for her
study. She currently uses the Framingham and Jackson Heart data but she also wants to bring
in more data than what is available in dbGaP.

**Current approach:**

Right now Ishanvi would have separate logins for the datasets she wants to use and each would
require separate approvals. She wouldn't have the ability to download all
the studies she wants or to store all of that data locally, but she also wouldn't have
the funds or technical support to use it in the cloud. She would perform
search queries over and over until she had the data she thought she needed and
download that to analyze with a software package she purchased. She would like
to have a single way to use that data together without downloading it
all to her computer. And it would have to be secure.

**With Data Commons Phase 1:**

Ishanvi can readily access data in the cloud. Multiple datasets are supported
and can be linked through a common metadata model. A query returns
data that matches Ishanviâ€™s data access approval and the study
consent. She can label her new cohort and use a secure workspace and pre-made tools to analyze it.

**With Data Commons longer vision:**

Data is FAIR, and is automatically put into a common data model and linked across
studies. Ishanvi can bring her
own data to the cloud workspace to expand her cohort, and the pool of
supported data sets is greatly expanded. She can now publish
her cohort for other researchers to use. They can find a cohort
defined for a different study, use the same workflow to reproduce the
results, and their own methodology to re-analyze the same data.
